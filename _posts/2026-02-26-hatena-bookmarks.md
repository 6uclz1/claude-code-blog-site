---
layout: post
title: "はてなブックマーク 2026年02月26日 の記事まとめ (5件)"
date: 2026-02-27 08:25:09 +0900
excerpt: "はてなブックマークで気になった記事をAIで要約してお届けします。2026年02月26日分の5件の記事をまとめました。

- Claude CodeのOSS版 OpenCodeの内部挙動を理解する

- WSL内で起動したClaude Codeの動作を高速化する簡単な設定

- https://openai.com/index/harness-engineering/

- Claude Code Flaws Allow Remote Code Execution and API Key Exfiltration

- ChatGPT - ハーネスエンジニアリングの現状
"
---

はてなブックマークで気になった記事をAIで要約してお届けします。
2026年02月26日分の5件の記事をまとめました。

## 1. Claude CodeのOSS版 OpenCodeの内部挙動を理解する

**URL:** [https://zenn.dev/epicai_techblog/articles/20b78066cac63f](https://zenn.dev/epicai_techblog/articles/20b78066cac63f)

### AI要約

*   **要点**
    *   OpenCodeはOSSのAIコーディングツールであり、そのTypeScript実装から内部動作を解析し、LLMエージェントの具体的なメカニズムを理解することが目的です。
    *   ユーザーのコーディング指示は、システムプロンプト構築、ツール選択、LLM呼び出し、ストリーミング処理、ツール実行、コンテキスト管理といった多段階の複雑なフローを経てコード化されます。
    *   LLMは自律的に「task」ツールを呼び出し、コードベースの調査を行う「explore」などのサブエージェントを活用することで、多角的な情報収集と問題解決を進めます。
    *   この洗練されたエージェント設計により、OpenCodeは高度なコーディング支援を可能にし、他の商用ツールに遜色ない精度を実現しています。

*   **詳細な要約**
    OpenCodeはOSSのAIコーディングツールであり、そのTypeScriptコードから内部動作を詳細に解説する記事です。本稿の目的は、LLMベースのコーディングエージェントがユーザー指示をどのようにコードに変換するのか、その具体的なメカニズムを実装レベルで理解することにあります。OpenCodeはGitHubで高い評価を得ており、多様な大規模言語モデル（LLM）に対応しながら、Claude CodeやCodexに遜色ない精度を持つ優良なエージェント設計が特徴です。

    記事では、ユーザーのコーディング指示（例：「APIハンドラーにレート制限を追加し、既存テストも通す」）が実行されるまでの多段階処理フローを追っています。このフローは、入力の受け取りから始まり、セッション管理、使用モデルに応じたシステムプロンプトの構築、標準・カスタムツールの解決とLLMの呼び出し、レスポンスのストリーミング処理、ツールの実行、そしてコンテキストウィンドウの管理といった複雑なステップで構成されます。

    特に注目すべきは、LLMが自律的に判断し、「task」ツールを使って「explore」のようなサブエージェントを呼び出す仕組みです。例えば、コードベース全体を調査する必要がある場合、LLMの指示に基づき、サブエージェントが独立してファイル探索や内容の読み取りを行い、その調査結果をメインのLLMにフィードバックします。この高度なエージェント設計により、OpenCodeはコードベースを深く理解し、ユーザーの複雑な要求に応じた精度の高いコーディング支援を実現しているのです。

---

## 2. WSL内で起動したClaude Codeの動作を高速化する簡単な設定

**URL:** [https://zenn.dev/momonga/articles/ee5b114e038938](https://zenn.dev/momonga/articles/ee5b114e038938)

### AI要約

*   WSL上でClaude Codeがフリーズや動作遅延を起こす問題は、簡単な設定で解消可能。
*   原因は、Claude Codeが頻繁にWindows側の`powershell.exe`を呼び出してユーザープロファイル情報を取得するため。
*   `.bashrc`に環境変数を追加することで、`powershell.exe`の不要な呼び出しを停止し、動作を高速化する。

WSL（Windows Subsystem for Linux）上で開発支援ツール「Claude Code」を使用する際に発生する、数秒間のフリーズや動作遅延を解消するための設定を解説した記事です。

記事によると、この問題は、Claude CodeがWSL内で動作中に、Windows側のユーザープロファイル情報を取得するために`powershell.exe`を頻繁に呼び出すことが原因です。この処理が同期的に行われるため、`powershell.exe`からの応答を待つ間、Claude CodeのUIがフリーズしてしまいます。特に、`powershell.exe`の起動時に読み込まれる設定ファイル（PowerShellプロファイル）に複雑な設定がされていると、処理時間が長くなり、フリーズが顕著になります。

この問題を解決するには、WSLの環境設定ファイル（例: `~/.bashrc`）に以下の環境変数を追加します。
`export CLAUDE_CODE_SKIP_WINDOWS_PROFILE=1`
`export USERPROFILE="/mnt/c/Users/<あなたのWindowsユーザー名>"`
これにより、Claude Codeが`powershell.exe`を介してWindowsのユーザープロファイル情報を取得するのを停止させ、不要な呼び出しによるオーバーヘッドをなくすことで、フリーズが解消され、快適に利用できるようになります。

---

## 3. https://openai.com/index/harness-engineering/

**URL:** [https://openai.com/index/harness-engineering/](https://openai.com/index/harness-engineering/)

### AI要約

**要点**

*   OpenAIは、手動で書かれたコードが一切ないソフトウェア製品を、AIエージェント「Codex」のみで開発する実験を実施しました。
*   この実験では、5ヶ月間で約100万行のコードがCodexによって生成され、通常の手書きコードに比べて開発期間を約10分の1に短縮しました。
*   エンジニアの役割は、コード作成から、エージェントが効率的に作業できるよう環境を設計し、明確な指示を与える「ハーネスエンジニアリング」へと変化しました。
*   このアプローチは、人間の時間と注意力を最大限に活用し、ソフトウェア開発の生産性を劇的に向上させる可能性を示しています。

**詳細な要約**

OpenAIのエンジニアリングチームは、AIエージェント「Codex」を活用し、手動で書かれたコードが一切ないソフトウェア製品を開発するという画期的な実験を行いました。この「ハーネスエンジニアリング」と呼ばれるアプローチの目的は、AIエージェントの能力を最大限に引き出し、ソフトウェア開発の速度を桁違いに向上させることです。

実験では、わずか5ヶ月間でアプリケーションロジック、テスト、設定、ドキュメント、さらには内部ツールに至るまで、製品を構成する約100万行ものコード全てがCodexによって生成されました。これにより、開発期間は従来の手書きコードに比べて約10分の1に短縮され、少ないエンジニアで迅速に製品が構築され、既に数百人の内部ユーザーに利用されています。

この試みを通じて、エンジニアの役割は大きく変わりました。彼らはもはやコードを直接書くのではなく、「操縦者」として、Codexエージェントが信頼性の高い作業を行えるよう、システム環境の設計、開発意図の明確な指示、そしてフィードバックループの構築に集中するようになりました。この新しい開発モデルは、人間が持つ最も希少なリソースである時間と注意力を最大限に活用し、AIが主導する未来のソフトウェア開発の可能性を鮮やかに示しています。

---

## 4. Claude Code Flaws Allow Remote Code Execution and API Key Exfiltration

**URL:** [https://thehackernews.com/2026/02/claude-code-flaws-allow-remote-code.html](https://thehackernews.com/2026/02/claude-code-flaws-allow-remote-code.html)

### AI要約

*   AnthropicのAIアシスタント「Claude」に、リモートコード実行とAPIキー流出を可能にする複数の深刻な脆弱性が発見されました。
*   これらの脆弱性は、外部サービス連携機能「Tools」のサンドボックス設計の不備に起因し、悪意のあるプロンプトで悪用される可能性がありました。
*   AIセキュリティ企業Trail of Bitsが発見・報告し、Anthropicは既に修正済みですが、AIシステムのセキュリティ対策の重要性を浮き彫りにしています。

Anthropicが提供するAIアシスタント「Claude」に、攻撃者が基盤となるシステム上で不正なコードを実行したり、機密性の高いAPIキーを不正に取得したりできる深刻なセキュリティ上の欠陥が複数発見されました。これはAIセキュリティ企業Trail of Bitsの研究者チームによって明らかにされたものです。

脆弱性の根本原因は、Claudeが外部サービスと連携する際に使用する「Tools」機能におけるサンドボックス（隔離された実行環境）設計の不完全さにありました。この不備により、悪意のあるプロンプト（指示）が利用されると、サンドボックスが迂回され、本来アクセスできないシステム領域でコードが実行されるリスクが存在しました。これにより、顧客データの不正アクセスや改ざん、サービス妨害、さらにはマルウェアの拡散といった重大な被害につながる恐れがありました。

Trail of Bitsはこれらの問題点をAnthropicに報告し、Anthropicは迅速に対応して修正パッチを適用し、脆弱性は既に解消されています。今回の発見は、AIモデル自体の安全性だけでなく、それに付随する外部連携機能やサンドボックス環境といった広範なセキュリティ対策がいかに重要であるかを浮き彫りにしており、AIシステムの開発者や利用者が、信頼できない入力を厳しく検証し、セキュリティ対策を一層強化する必要があることを強く示唆しています。

---

## 5. ChatGPT - ハーネスエンジニアリングの現状

**URL:** [https://chatgpt.com/share/699fa6c6-454c-800b-bc60-6520949aa353](https://chatgpt.com/share/699fa6c6-454c-800b-bc60-6520949aa353)

### AI要約

**要点**

*   AIチャットボット「ChatGPT」の利用は、ユーザーによる利用規約への同意とプライバシーポリシーの確認が前提となる。
*   ChatGPTは、メッセージングに加え、ファイル添付、検索、画像生成、音声入力など多様な機能を提供していることが示唆されている。

**詳細な要約**

提供されたテキストは、AIチャットボット「ChatGPT」をユーザーが利用する際の、基本的な法的条件と機能の概要を提示しています。この記述の中心は「By messaging ChatGPT, an AI chatbot, you agree to our Terms and have read our Privacy Policy.」という一文であり、ユーザーがChatGPTにメッセージを送信する行為自体が、サービス提供者が定めた利用規約（Terms）に同意し、そのプライバシーポリシーを読み、理解したことの表明となることを明確に示しています。これは、AIサービスを利用する上で不可欠な、ユーザーとサービス提供者間の基本的な合意形成であり、データ利用や責任範囲に関する理解を前提とするものです。

さらに、テキスト冒頭の「AttachSearchStudyCreate imageVoice」というフレーズは、ChatGPTが単なるテキストベースのメッセージングツールに留まらない、多機能性を有していることを示唆しています。具体的には、ファイルの添付（Attach）、情報の検索（Search）、学習や分析（Study）、新たな画像の生成（Create image）、そして音声による対話（Voice）といった、多様なインタラクションモードが提供されている可能性がうかがえます。これにより、ユーザーはより高度でインタラクティブな方法でAIと連携し、幅広いタスクを実行できることが期待されます。この短いテキストは、ChatGPTの利用開始における法的同意と、その広範な機能のヒントを伝える内容と言えるでしょう。

---

*この記事は、はてなブックマークのRSSフィードから自動生成されました。*  
*要約はAI（Gemini）によって生成されており、元記事の内容を正確に反映していない場合があります。*  
*詳細な内容については、各URLから元記事をご確認ください。*
