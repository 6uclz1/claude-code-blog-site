---
layout: post
title: "はてなブックマーク 2025年09月27日 の記事まとめ (5件)"
date: 2025-09-28 08:13:08 +0900
excerpt: "はてなブックマークで気になった記事をAIで要約してお届けします。2025年09月27日分の5件の記事をまとめました。

- 作曲AIが新時代に突入。SunoがMIDI出力とマルチトラック編集（DAW）に対応、Tuneeは6曲同時生成で一般公開（CloseBox） | テクノエッジ TechnoEdge

- Code Mode: the better way to use MCP

- Gemini Robotics 1.5 を発表、AI エージェントを物理世界に

- GitHub Copilot CLI is now in public preview - GitHub Changelog

- 『GitHub Copilot CLI is now in public preview - GitHub Changelog』へのコメント
"
---

はてなブックマークで気になった記事をAIで要約してお届けします。
2025年09月27日分の5件の記事をまとめました。

## 1. 作曲AIが新時代に突入。SunoがMIDI出力とマルチトラック編集（DAW）に対応、Tuneeは6曲同時生成で一般公開（CloseBox） | テクノエッジ TechnoEdge

**URL:** [https://www.techno-edge.net/article/2025/09/26/4614.html](https://www.techno-edge.net/article/2025/09/26/4614.html)

### AI要約

## 要点：

*   **SunoのDAW内蔵とMIDI出力対応:** AI作曲サービスSunoが、マルチトラック編集（DAW）機能とMIDIエクスポートに対応し、より高度な楽曲編集が可能になりました。
*   **Tuneeの一般公開と同時6曲生成:** 対話型AI作曲サービスTuneeが一般公開され、一つのプロンプトから歌詞・音楽スタイルそれぞれ2曲ずつ、合計6曲を同時生成する機能を提供します。
*   **AI作曲の新たな進化:** 両サービスの機能強化により、AI作曲がより柔軟で効率的な制作ツールへと進化し、新時代の幕開けを告げています。

## 詳細な要約：

AI作曲サービスのSunoとTuneeが、それぞれ画期的な新機能を発表し、作曲AIの新時代を切り開いています。

Sunoは、待望のDAW（Digital Audio Workstation）機能の内蔵とMIDI出力に対応しました。これにより、生成された楽曲やインポートしたオーディオをSTEM分離し、マルチトラックでピッチやテンポの変更が可能になります。特に注目すべきは、新規トラックに楽器を「生成」できる機能で、指定したスタイル（例：ハモンドオルガン）で文脈を理解した演奏を追加できます。また、STEM分離でMIDIエクスポートが可能になり、ドラムや鍵盤楽器のMIDIデータ活用が容易になりました。まだ開発途中であり、一部不具合も報告されていますが、DAW機能とMIDI対応の第一歩として今後の進化が期待されます。

一方、これまでクローズドベータだった対話型AI作曲サービスTuneeは、ついに一般公開されました。日本語にフル対応し、モバイルビューからもアクセス可能です。最大の特徴は、一つのプロンプトから3種類の音楽スタイルと歌詞をそれぞれ2曲ずつ、合計6曲を同時に生成できる「全部入り」オプションです。これにより、短時間で多様な楽曲アイデアを生み出すことが可能となり、ユーザーはより多くの選択肢の中から名曲を発見する機会を得られます。Tuneeで生成した楽曲の歌詞の修正など、Sunoとの連携による制作ワークフローの可能性も示唆されており、両サービスが互いに補完し合いながらAI作曲の未来を牽引していくことが予想されます。

---

## 2. Code Mode: the better way to use MCP

**URL:** [https://blog.cloudflare.com/code-mode/](https://blog.cloudflare.com/code-mode/)

### AI要約

**要点**

*   AIエージェントが外部ツール（Model Context Protocol: MCP）を利用する際、LLMが直接ツールを呼び出すのではなく、TypeScript APIを介してコードを書く新しい「Code Mode」を提案。
*   この新しいアプローチにより、LLMはより多くの複雑なツールを効率的に扱え、連続した操作もスムーズに実行できるようになる。
*   LLMは、直接ツールを呼び出すよりも、ツールを呼び出すためのコードを生成する方が得意であるという知見に基づいている。
*   MCPは、AIエージェントが外部ツールにアクセスし、チャットだけでなく具体的な作業を実行できるようにする標準プロトコルである。

**詳細な要約**

Cloudflareの記事は、AIエージェントが外部ツールを利用するための「Model Context Protocol (MCP)」のより効果的な使用法「Code Mode」を提唱しています。MCPとは、AIエージェントが外部のAPIを通じて具体的な作業を実行できるようにする標準プロトコルです。

従来のMCPの利用方法では、LLMにツールを直接公開していましたが、これにより扱えるツールの数や複雑さに限界があり、特に複数のツールを連続して使用する際に効率が悪いという問題がありました。各ツールの出力が一度LLMの処理を経由するため、時間や計算資源の無駄が生じていました。

Code Modeでは、MCPツールをTypeScript APIに変換し、LLMにそのAPIを呼び出すコードを書かせるアプローチを取ります。この画期的な方法により、LLMはより多くの、そしてより複雑なツールを効率的に扱えるようになります。これは、LLMが膨大な量のTypeScriptコードで学習しているため、直接ツールを呼び出すよりもコード生成の方が得意であるという知見に基づいています。連続するツール呼び出しも、LLMがコード内で直接結果を受け渡せるため、大幅に効率化され、時間やリソースの無駄が削減されます。

要するに、LLMがMCPを直接利用するよりも、TypeScriptコードとしてAPIを操作する方が、その能力を最大限に引き出し、AIエージェントの機能を大幅に拡張する道を開く、と記事は結んでいます。

---

## 3. Gemini Robotics 1.5 を発表、AI エージェントを物理世界に

**URL:** [https://blog.google/intl/ja-jp/company-news/technology/gemini-robotics-15-ai/](https://blog.google/intl/ja-jp/company-news/technology/gemini-robotics-15-ai/)

### AI要約

**要点**

*   Google DeepMindが、AIエージェントを物理世界で機能させるための2つの新ロボットモデル「Gemini Robotics 1.5」と「Gemini Robotics-ER 1.5」を発表しました。
*   Gemini Robotics 1.5は、ロボットが視覚情報と指示から具体的な動作を考え、実行する能力を持ち、思考プロセスを可視化できます。
*   Gemini Robotics-ER 1.5は、物理世界を推論し、詳細な多段階の計画を立てる「頭脳」の役割を果たし、デジタルツールや検索も活用します。
*   両モデルは連携し、人間が与える複雑な指示（例：ゴミの分別）をロボットが自律的に理解し、計画し、実行できるようにします。
*   Gemini Robotics-ER 1.5は開発者向けにGoogle AI Studioで提供開始されており、物理世界における複雑なタスク遂行能力の向上を目指します。

**詳細な要約**

Google DeepMindは、AIエージェントが物理世界でより高度に機能するための新たなロボットモデルファミリー「Gemini Robotics 1.5」と「Gemini Robotics-ER 1.5」を発表しました。これは、ロボットが複雑なタスクを自律的に遂行し、インテリジェントなエージェント体験を実現することを目的としています。

「Gemini Robotics 1.5」は、最も高性能な視覚・言語・行動（VLA）モデルであり、ロボットが視覚情報と指示を具体的な動作命令に変換する能力を持ちます。このモデルは、行動する前に思考し、その思考プロセスを言葉で説明できるため、ロボットの意思決定の透明性が高まります。また、複数の機体で学習できるため、スキルの習得が加速されます。

一方、「Gemini Robotics-ER 1.5」は、最も高性能な視覚・言語モデル（VLM）で、ロボット全体の「頭脳」として機能します。物理世界を推論し、ネイティブにデジタルツール（Google検索など）を呼び出し、ミッションを完了するための詳細な多段階の計画を作成します。最先端の空間理解能力を持ち、論理的な意思決定と計画立案に優れています。

この2つのモデルは連携して動作します。Gemini Robotics-ER 1.5がタスクの全体的な計画を立て、それを自然言語の指示に変換してGemini Robotics 1.5に伝えます。Gemini Robotics 1.5はその指示を受け、優れた視覚と言語理解能力を用いて具体的なアクションを実行します。例えば、「この地域のルールに合わせてゴミを分別して」といった複雑な指示に対し、ロボットはまずインターネットで地域のルールを検索し、ゴミの種類を認識し、分別方法を判断し、最終的にゴミを捨てるという一連の行動を自律的に行えるようになります。

Gemini Robotics-ER 1.5は、現在開発者向けにGoogle AI Studioを通じて提供されており、物理世界におけるロボットの理解力と実行能力を大幅に向上させることを目指しています。

---

## 4. GitHub Copilot CLI is now in public preview - GitHub Changelog

**URL:** [https://github.blog/changelog/2025-09-25-github-copilot-cli-is-now-in-public-preview/](https://github.blog/changelog/2025-09-25-github-copilot-cli-is-now-in-public-preview/)

### AI要約

*   GitHub Copilot CLIが公開プレビューとなり、ターミナルで直接AIエージェントが利用可能に。
*   GitHubのコンテキストを理解し、自然言語でリポジトリやイシューなどを操作できる。
*   コードの構築、編集、デバッグ、リファクタリングといった複雑なタスクをAIが支援。
*   実行前にユーザーが各アクションを承認するため、完全に制御可能。
*   既存のCopilotプラン契約者であれば、すぐに利用開始できる。

---

GitHub Copilot CLIが公開プレビューを開始し、開発者はターミナル内で直接AIによるコーディング支援を受けられるようになりました。このツールは、GitHubのコンテキスト（リポジトリ、イシュー、プルリクエストなど）を理解し、自然言語でそれらにアクセスできるため、コンテキスト切り替えなしで作業を進められます。

Copilot CLIは、単なるコード補完を超え、AIエージェントとしてコードの構築、編集、デバッグ、リファクタリングといった複雑なタスクの計画と実行を支援します。例えば、新しいコードベースの探索、イシューに基づく機能実装、ローカルでのデバッグ作業など、多様な開発シナリオでインテリジェントなアシストを提供します。また、機能拡張のためのMCPサーバーにも対応しています。

利用は簡単で、npm経由でインストール後、既存のGitHubアカウントで認証するだけです。Copilot Pro、Pro+、Business、またはEnterpriseのいずれかのプランを契約していれば、すぐに利用を開始できます。何よりも重要なのは、AIが提案するすべてのアクションは、実行前にユーザーの明示的な承認を必要とするため、開発者が完全に制御できる点です。これにより、開発者は安心してAIの能力を最大限に活用し、生産性を向上させることが可能です。

---

## 5. 『GitHub Copilot CLI is now in public preview - GitHub Changelog』へのコメント

**URL:** [https://b.hatena.ne.jp/entry/s/github.blog/changelog/2025-09-25-github-copilot-cli-is-now-in-public-preview/](https://b.hatena.ne.jp/entry/s/github.blog/changelog/2025-09-25-github-copilot-cli-is-now-in-public-preview/)

### AI要約

**要点**

*   GitHub Copilotのコマンドラインインターフェース（CLI）版がパブリックプレビューとして利用可能になりました。
*   この新機能により、AIコーディングエージェントがターミナル上で直接動作し、開発者のローカル作業を効率的に支援します。
*   ユーザーからはターミナル作業の生産性向上への期待が寄せられる一方で、ドキュメントの不足など、初期段階における課題も指摘されています。

**詳細な要約**

GitHub Copilot CLIがパブリックプレビューとなり、AIによるコーディング支援が開発者のターミナルに直接もたらされることになりました。これは、GitHub Copilotの強力なAIエージェントが、コードやGitHubのコンテキストを理解し、ローカルでの開発作業をリアルタイムでサポートすることを意味します。この発表に対し、日本の開発者コミュニティからは大きな関心が寄せられています。

はてなブックマークでのユーザーの反応を見ると、「ターミナル作業が捗る」といった生産性向上への期待の声が多く見られます。CLIでのAIアシスタンスは、特にターミナルを多用する開発者にとって、ワークフローをスムーズにし、効率を高める可能性を秘めています。しかし、現状ではまだドキュメントが不十分で、設定に関する情報が限られているといった指摘もあり、今後の情報拡充や機能改善に期待が寄せられています。一部にはGitHub Copilot全体への懐疑的な意見も見られますが、ターミナルネイティブな開発体験を強化するこの新機能の潜在的な価値に関心が集まっています。

---

*この記事は、はてなブックマークのRSSフィードから自動生成されました。*  
*要約はAI（Gemini）によって生成されており、元記事の内容を正確に反映していない場合があります。*  
*詳細な内容については、各URLから元記事をご確認ください。*
